#!/usr/bin/env python3
"""
Test Ollama Connection for Waiter Integration
"""

import requests
import json

def test_ollama_connection():
    """Test if Ollama is running and accessible"""
    
    print("üîç TESTING OLLAMA CONNECTION")
    print("=" * 40)
    
    try:
        # Test basic connection
        print("üì° Testing Ollama API connection...")
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        
        if response.status_code == 200:
            print("‚úÖ Ollama is running!")
            
            # Get available models
            models = response.json()
            print(f"üì¶ Available models: {len(models.get('models', []))}")
            
            for model in models.get('models', []):
                print(f"  - {model.get('name', 'Unknown')}")
            
            # Test if qwen2.5:7b is available (used in quantum kitchen)
            model_names = [model.get('name', '') for model in models.get('models', [])]
            if 'qwen2.5:7b' in model_names:
                print("‚úÖ qwen2.5:7b model found - Waiter ready!")
            else:
                print("‚ö†Ô∏è  qwen2.5:7b not found - Waiter may need different model")
                
        else:
            print(f"‚ùå Ollama API error: {response.status_code}")
            
    except requests.exceptions.ConnectionError:
        print("‚ùå Ollama not running or not accessible")
        print("üí° Start Ollama with: ollama serve")
        
    except Exception as e:
        print(f"‚ùå Error testing Ollama: {e}")

if __name__ == "__main__":
    test_ollama_connection() 